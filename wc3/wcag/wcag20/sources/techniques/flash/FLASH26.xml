<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE technique
  SYSTEM "../../xmlspec.dtd">
<technique id="FLASH26">
   <short-name>Applying audio descriptions to Flash video</short-name>
   <applicability>
      <ulist>
         <item>
            <p> Flash CS3 and higher </p>
         </item>
         <item>
            <p> ActionScript 3.0 and higher </p>
         </item>
      </ulist>
   </applicability>
   <applies-to>
      <success-criterion idref="media-equiv-audio-desc" relationship="sufficient"/>
      <success-criterion idref="media-equiv-audio-desc-only" relationship="sufficient"/>
   </applies-to>
   <ua-issues>
      <ua-issue use-id="flash.ua-issue.general"/>
   </ua-issues>
   <description>
      <p>The objective of this technique is to provide a way for people
    				who are blind or otherwise have trouble seeing the video in
    				audio-visual material to be able to access the material. With
    				this technique a description of the video is provided via audio
    				description that will fit into the gaps in the dialogue in
    				the audio-visual material. </p>
   </description>
   <examples>
      <eg-group>
         <head>Playing descriptions when cue points are reached</head>
         <description>
            <p>In this example, the FLVPlayback component is used to create
    						a video player. A custom class called "AudioDescriptions" is
    						added to manage the playback of extended audio descriptions.
    						This class provides event listeners to listen for cue points
    						in the media that have been identified by the audio description
    						provider. When these cuepoints are reached, an mp3 file containing
    						the corresponding description will start playing. The recorded
    						descriptions have been timed to fit with in the gaps in the
    						movie's dialog. </p>
            <p>By default, audio descriptions will be enabled. A button (which
    						must itself be accessible to meet other success criteria) is
    						provided below the video player that allows the user to turn
    						audio descriptions on or off. </p>
         </description>
         <code xml:space="preserve"><![CDATA[package {
  import fl.video. *;
  import flash.events. *;
  import flash.media.Sound;
  import flash.media.SoundChannel;
  import flash.net.URLRequest;
  import flash.display.Sprite;
  
  public class AudioDescriptions extends Sprite {
    private var channel: SoundChannel = new SoundChannel;
    private var myPlayer: FLVPlayback;
    private var _enabled: Boolean = true;
    private var _toggleBtn: Button;
    private var snd: Sound = new Sound();
    public function AudioDescriptions() {
      // point myPlayer to the FLVPlayback component instance on the stage, 
      // which should be loaded with a valid video source.
      myPlayer = my_FLVPlybk;
      // add cue points. When any of these are reached, the 
      // MetadataEvent.CUE_POINT event will fire
      myPlayer.addASCuePoint(8.35, "ASpt1");
      myPlayer.addASCuePoint(23.23, "ASpt2");
      
      enable();
      
      enable_AD_btn.addEventListener(MouseEvent.CLICK, handleBtnClick);
    }
    
    private function handleBtnClick(e) {
      _enabled = ! _enabled;
      if (! _enabled) {
        disable();
        enable_AD_btn.label = "Enable Audio Descriptions";
      } else {
        enable();
        enable_AD_btn.label = "Disable Audio Descriptions";
      }
    }
    
    public function enable() {
      // set up an event handler which will be called each time a cue point is reached
      myPlayer.addEventListener(MetadataEvent.CUE_POINT, cp_listener);
    }
    
    public function disable() {
      // remove the event handler called each time a cue point is reached, so 
      // that audio description is disabled.
      myPlayer.removeEventListener(MetadataEvent.CUE_POINT, cp_listener);
    }
    
    private function cp_listener(eventObject: MetadataEvent): void {
      snd = new Sound();
      //recreate sound object as it can only load one mp3 file
      //check to see which cue point was reached
      switch (eventObject.info.name) {
        case "ASpt1":
        snd.load(new URLRequest("sphere.mp3"));
        //create a new Sound object, and load the appropriate mp3
        channel = snd.play();
        // play the audio description, and assign it to the SoundChannel object
        break;
        case "ASpt2":
        snd.load(new URLRequest("transfrm.mp3"));
        channel = snd.play();
        break;
      }
    }
  }
}]]></code>
         <description>
            <p>The result can be viewed in the <loc xmlns:xlink="http://www.w3.org/1999/xlink"
                    href="audio_descriptions_as3.html"
                    linktype="examples">working version of Playing descriptions when cue points are reached</loc>. The <loc xmlns:xlink="http://www.w3.org/1999/xlink"
                    href="audio_descriptions_as3.zip"
                    linktype="examples">source of Playing descriptions when cue points are reached</loc> is available.</p>
         </description>
      </eg-group>
      <eg-group>
         <head>Providing an additional audio track for descriptions</head>
         <description>
            <p>Audio description can also be provided via an additional audio
    						track that is the same length and plays simultaneously as the
    						primary media, but that only includes sound for the segments
    						when audio description needs to be played and silence at other
    						times. A Flash author can provide a toggle to turn this additional
    						audio track on or off, based on the listener's preference.
    						When the additional track is enabled, there are two parallel
    						audio tracks, one being the primary audio, and the second being
    						the one containing only audio description. It is still necessary
    						to ensure that the audio description and primary audio do not
    						overlap in ways that make comprehension difficult. This method
    						will achieve the same result as the method used in Example
    						1, but may be chosen because of the type of audio description
    						files that are provided to the Flash author. </p>
         </description>
      </eg-group>
   </examples>
   <related-techniques>
      <relatedtech idref="G78"/>
      <relatedtech idref="G69"/>
      <relatedtech idref="G173"/>
   </related-techniques>
   <tests>
      <procedure>
         <p>When Flash content contains video with an audio soundtrack,
    					confirm that: </p>
         <olist>
            <item>
               <p> Audio descriptions have been made available using separate
    					sound files. </p>
            </item>
            <item>
               <p> A button is provided that allows users to enable or disable
    					the audio descriptions </p>
            </item>
         </olist>
      </procedure>
      <expected-results>
         <ulist>
            <item>
               <p> #1 and #2 are true </p>
            </item>
         </ulist>
      </expected-results>
   </tests>
   <admin>
      <source>
						   <loc xmlns:xlink="http://www.w3.org/1999/xlink"
              href="http://trace.wisc.edu/wcag_wiki/index.php?title=Applying_audio_descriptions_to_Flash_video"/>
					</source>
   </admin>
</technique>
